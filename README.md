# Aplicación Interactiva para Presentaciones mediante Gestos, Voz y Sensores Móviles  
**Periodo:** Febrero 2025 – Abril 2025  

## Tecnologías utilizadas
- Backend: Node.js, Express.js  
- Comunicación en tiempo real: Socket.IO  
- Interfaz web: HTML, CSS, JavaScript  
- Detección de gestos: MediaPipe Hands  
- Sensores móviles: acelerómetro y giroscopio  
- APIs: SpeechRecognition (transcripción de voz), Translated.net (traducción automática)  
- Infraestructura y pruebas: Ngrok  

## Descripción del proyecto
Prototipo funcional que permite controlar presentaciones en tiempo real utilizando únicamente un dispositivo móvil.  

### Funcionalidades principales
- Control de diapositivas mediante gestos detectados con MediaPipe.  
- Uso del giroscopio como puntero láser virtual.  
- Transcripción automática del discurso con traducción multilingüe.  
- Arquitectura cliente-servidor con Node.js y Socket.IO para baja latencia y portabilidad.  

### Optimización
Tras pruebas iterativas con usuarios, se mejoró la precisión del reconocimiento de gestos y la calibración del puntero, logrando una experiencia fluida y natural.  
